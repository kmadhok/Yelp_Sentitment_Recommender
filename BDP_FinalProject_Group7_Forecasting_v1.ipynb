{"cells": [{"cell_type": "code", "execution_count": 1, "id": "71795a95-3c94-456b-ba7b-3be773ffcf37", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession \nfrom pyspark.sql.functions import when\n\nspark = SparkSession.builder.appName('Yelp Businesses EDA').getOrCreate()\nsc = spark.sparkContext "}, {"cell_type": "code", "execution_count": 11, "id": "a45fc048-7209-4287-b96b-652e5ca12343", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- address: string (nullable = true)\n |-- attributes: struct (nullable = true)\n |    |-- AcceptsInsurance: string (nullable = true)\n |    |-- AgesAllowed: string (nullable = true)\n |    |-- Alcohol: string (nullable = true)\n |    |-- Ambience: string (nullable = true)\n |    |-- BYOB: string (nullable = true)\n |    |-- BYOBCorkage: string (nullable = true)\n |    |-- BestNights: string (nullable = true)\n |    |-- BikeParking: string (nullable = true)\n |    |-- BusinessAcceptsBitcoin: string (nullable = true)\n |    |-- BusinessAcceptsCreditCards: string (nullable = true)\n |    |-- BusinessParking: string (nullable = true)\n |    |-- ByAppointmentOnly: string (nullable = true)\n |    |-- Caters: string (nullable = true)\n |    |-- CoatCheck: string (nullable = true)\n |    |-- Corkage: string (nullable = true)\n |    |-- DietaryRestrictions: string (nullable = true)\n |    |-- DogsAllowed: string (nullable = true)\n |    |-- DriveThru: string (nullable = true)\n |    |-- GoodForDancing: string (nullable = true)\n |    |-- GoodForKids: string (nullable = true)\n |    |-- GoodForMeal: string (nullable = true)\n |    |-- HairSpecializesIn: string (nullable = true)\n |    |-- HappyHour: string (nullable = true)\n |    |-- HasTV: string (nullable = true)\n |    |-- Music: string (nullable = true)\n |    |-- NoiseLevel: string (nullable = true)\n |    |-- Open24Hours: string (nullable = true)\n |    |-- OutdoorSeating: string (nullable = true)\n |    |-- RestaurantsAttire: string (nullable = true)\n |    |-- RestaurantsCounterService: string (nullable = true)\n |    |-- RestaurantsDelivery: string (nullable = true)\n |    |-- RestaurantsGoodForGroups: string (nullable = true)\n |    |-- RestaurantsPriceRange2: string (nullable = true)\n |    |-- RestaurantsReservations: string (nullable = true)\n |    |-- RestaurantsTableService: string (nullable = true)\n |    |-- RestaurantsTakeOut: string (nullable = true)\n |    |-- Smoking: string (nullable = true)\n |    |-- WheelchairAccessible: string (nullable = true)\n |    |-- WiFi: string (nullable = true)\n |-- business_id: string (nullable = true)\n |-- categories: string (nullable = true)\n |-- city: string (nullable = true)\n |-- hours: struct (nullable = true)\n |    |-- Friday: string (nullable = true)\n |    |-- Monday: string (nullable = true)\n |    |-- Saturday: string (nullable = true)\n |    |-- Sunday: string (nullable = true)\n |    |-- Thursday: string (nullable = true)\n |    |-- Tuesday: string (nullable = true)\n |    |-- Wednesday: string (nullable = true)\n |-- is_open: long (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- name: string (nullable = true)\n |-- postal_code: string (nullable = true)\n |-- review_count: long (nullable = true)\n |-- stars: double (nullable = true)\n |-- state: string (nullable = true)\n\n"}], "source": "# read data and see schema \ndf = spark.read.json('gs://msca-bdp-student-gcs/GroupProject_Gr7/yelp_dataset/yelp_academic_dataset_business.json') \nparquet_file_bus='gs://msca-bdp-student-gcs/GroupProject_Gr7/yelp_dataset/engineered_data/business.snappy.parquet'\nparquet_file_review='gs://msca-bdp-student-gcs/GroupProject_Gr7/yelp_dataset/engineered_data/review.snappy.parquet'\nparquet_file_user='gs://msca-bdp-student-gcs/GroupProject_Gr7/yelp_dataset/engineered_data/user.snappy.parquet'\ndf1=spark.read.option('multiline','true').option(\"quote\", \"\\\"\").option('escape','\\\"').option('ignoreLeadingWhiteSpace', 'true').option('header', True).option('escapeQuotes', 'true').parquet(parquet_file)\ndf_review=spark.read.option('multiline','true').option(\"quote\", \"\\\"\").option('escape','\\\"').option('ignoreLeadingWhiteSpace', 'true').option('header', True).option('escapeQuotes', 'true').parquet(parquet_file_review)\ndf_user=spark.read.option('multiline','true').option(\"quote\", \"\\\"\").option('escape','\\\"').option('ignoreLeadingWhiteSpace', 'true').option('header', True).option('escapeQuotes', 'true').parquet(parquet_file_user)\n\ndf.printSchema() "}, {"cell_type": "code", "execution_count": 12, "id": "2b86c94b-5ed1-437e-bdb2-52d00a4006d7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- user_id: string (nullable = true)\n |-- average_stars: double (nullable = true)\n |-- compliment_cool: long (nullable = true)\n |-- compliment_cute: long (nullable = true)\n |-- compliment_funny: long (nullable = true)\n |-- compliment_hot: long (nullable = true)\n |-- compliment_list: long (nullable = true)\n |-- compliment_more: long (nullable = true)\n |-- compliment_note: long (nullable = true)\n |-- compliment_photos: long (nullable = true)\n |-- compliment_plain: long (nullable = true)\n |-- compliment_profile: long (nullable = true)\n |-- compliment_writer: long (nullable = true)\n |-- cool: long (nullable = true)\n |-- elite: string (nullable = true)\n |-- fans: long (nullable = true)\n |-- friends: string (nullable = true)\n |-- funny: long (nullable = true)\n |-- name: string (nullable = true)\n |-- review_count: long (nullable = true)\n |-- useful: long (nullable = true)\n |-- yelping_since: string (nullable = true)\n\n"}], "source": "df_user.printSchema()"}, {"cell_type": "code", "execution_count": 4, "id": "5401e164-3e29-48ae-ae5c-c60863e214d1", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 2:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------------+----------------------+----------------------------------------------------------------------------+------------+-------+----------+-----------+------------------+-----------+------------+-----+-----+----------------+-----------+-------+--------+----+-----------+----------+-----------+----------------------+--------------------------+------------------------------------------------------------------------------------+-----------------+------+---------+-------+-------------------+-----------+---------+--------------+-----------+-----------+-----------------+---------+-----+-----+----------+-----------+--------------+-----------------+-------------------------+-------------------+------------------------+----------------------+-----------------------+-----------------------+------------------+-------+--------------------+-------+--------+--------+--------+--------+--------+--------+---------+\n|address            |business_id           |categories                                                                  |city        |is_open|latitude  |longitude  |name              |postal_code|review_count|stars|state|AcceptsInsurance|AgesAllowed|Alcohol|Ambience|BYOB|BYOBCorkage|BestNights|BikeParking|BusinessAcceptsBitcoin|BusinessAcceptsCreditCards|BusinessParking                                                                     |ByAppointmentOnly|Caters|CoatCheck|Corkage|DietaryRestrictions|DogsAllowed|DriveThru|GoodForDancing|GoodForKids|GoodForMeal|HairSpecializesIn|HappyHour|HasTV|Music|NoiseLevel|Open24Hours|OutdoorSeating|RestaurantsAttire|RestaurantsCounterService|RestaurantsDelivery|RestaurantsGoodForGroups|RestaurantsPriceRange2|RestaurantsReservations|RestaurantsTableService|RestaurantsTakeOut|Smoking|WheelchairAccessible|WiFi   |Friday  |Monday  |Saturday|Sunday  |Thursday|Tuesday |Wednesday|\n+-------------------+----------------------+----------------------------------------------------------------------------+------------+-------+----------+-----------+------------------+-----------+------------+-----+-----+----------------+-----------+-------+--------+----+-----------+----------+-----------+----------------------+--------------------------+------------------------------------------------------------------------------------+-----------------+------+---------+-------+-------------------+-----------+---------+--------------+-----------+-----------+-----------------+---------+-----+-----+----------+-----------+--------------+-----------------+-------------------------+-------------------+------------------------+----------------------+-----------------------+-----------------------+------------------+-------+--------------------+-------+--------+--------+--------+--------+--------+--------+---------+\n|935 Race St        |MTSW4McQd7CbVtyjqoe9mw|Restaurants, Food, Bubble Tea, Coffee & Tea, Bakeries                       |Philadelphia|1      |39.9555052|-75.1555641|St Honore Pastries|19107      |80          |4.0  |PA   |null            |null       |u'none'|null    |null|null       |null      |True       |null                  |False                     |{'garage': False, 'street': True, 'validated': False, 'lot': False, 'valet': False} |False            |True  |null     |null   |null               |null       |null     |null          |null       |null       |null             |null     |null |null |null      |null       |False         |null             |null                     |False              |null                    |1                     |null                   |null                   |True              |null   |null                |u'free'|7:0-21:0|7:0-20:0|7:0-21:0|7:0-21:0|7:0-20:0|7:0-20:0|7:0-20:0 |\n|615 S Main St      |CF33F8-E6oudUQ46HnavjQ|Burgers, Fast Food, Sandwiches, Food, Ice Cream & Frozen Yogurt, Restaurants|Ashland City|1      |36.269593 |-87.058943 |Sonic Drive-In    |37015      |6           |2.0  |TN   |null            |null       |u'none'|None    |null|null       |null      |False      |null                  |True                      |None                                                                                |False            |False |False    |null   |null               |False      |True     |null          |True       |null       |null             |False    |True |null |null      |null       |True          |u'casual'        |null                     |True               |True                    |1                     |False                  |False                  |True              |null   |True                |u'no'  |9:0-0:0 |0:0-0:0 |9:0-22:0|8:0-22:0|6:0-22:0|6:0-22:0|6:0-22:0 |\n|2312 Dickerson Pike|bBDDEgkFA1Otx9Lfe7BZUQ|Ice Cream & Frozen Yogurt, Fast Food, Burgers, Restaurants, Food            |Nashville   |1      |36.2081024|-86.7681696|Sonic Drive-In    |37207      |10          |1.5  |TN   |null            |null       |u'none'|null    |null|null       |null      |null       |null                  |True                      |{'garage': False, 'street': False, 'validated': False, 'lot': False, 'valet': False}|False            |False |False    |null   |null               |False      |True     |null          |True       |null       |null             |False    |True |null |null      |null       |True          |'casual'         |null                     |True               |False                   |1                     |False                  |False                  |True              |null   |True                |u'no'  |6:0-16:0|0:0-0:0 |6:0-17:0|6:0-21:0|6:0-16:0|6:0-21:0|6:0-21:0 |\n+-------------------+----------------------+----------------------------------------------------------------------------+------------+-------+----------+-----------+------------------+-----------+------------+-----+-----+----------------+-----------+-------+--------+----+-----------+----------+-----------+----------------------+--------------------------+------------------------------------------------------------------------------------+-----------------+------+---------+-------+-------------------+-----------+---------+--------------+-----------+-----------+-----------------+---------+-----+-----+----------+-----------+--------------+-----------------+-------------------------+-------------------+------------------------+----------------------+-----------------------+-----------------------+------------------+-------+--------------------+-------+--------+--------+--------+--------+--------+--------+---------+\nonly showing top 3 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df1.show(3, truncate = False) "}, {"cell_type": "code", "execution_count": 5, "id": "b6aeef4f-d405-4508-9d22-a990e039ae3b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Default parallelism: 4\nNumber of partitions: 1 \n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 9:=======================================>               (143 + 4) / 200]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+-----+\n|partitionId|count|\n+-----------+-----+\n|          3| 4373|\n|          5| 4373|\n|          4| 4373|\n|          1| 4373|\n|          2| 4373|\n|          6| 4374|\n|          0| 4374|\n|          7| 4374|\n+-----------+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.sql import functions as F \n\n# determine number of partitions \ndef displayPartitions(df1): \n    num = df1.rdd.getNumPartitions() \n    df1.withColumn('partitionId', F.spark_partition_id()).groupby('partitionId').count().orderBy(F.asc('count')).show(num)  \n    \nprint('Default parallelism:', sc.defaultParallelism)\nprint('Number of partitions:', df1.rdd.getNumPartitions(), '\\n') \n\ndf1 = df1.repartition((sc.defaultParallelism * 2)) \ndisplayPartitions(df1)"}, {"cell_type": "code", "execution_count": 6, "id": "6a012683-ee3c-4b8a-8334-d76f34022fca", "metadata": {}, "outputs": [], "source": "from pyspark.sql import functions as F\n\n# Unwrap nested struct columns\ndf = df.withColumn('AcceptsInsurance', F.col('attributes.AcceptsInsurance'))\ndf = df.withColumn('AgesAllowed', F.col('attributes.AgesAllowed'))\ndf = df.withColumn('Alcohol', F.col('attributes.Alcohol'))\ndf = df.withColumn('Ambience', F.col('attributes.Ambience'))\ndf = df.withColumn('BYOB', F.col('attributes.BYOB'))\ndf = df.withColumn('BYOBCorkage', F.col('attributes.BYOBCorkage'))\ndf = df.withColumn('BestNights', F.col('attributes.BestNights'))\ndf = df.withColumn('BikeParking', F.col('attributes.BikeParking'))\ndf = df.withColumn('BusinessAcceptsBitcoin', F.col('attributes.BusinessAcceptsBitcoin'))\ndf = df.withColumn('BusinessAcceptsCreditCards', F.col('attributes.BusinessAcceptsCreditCards'))\ndf = df.withColumn('BusinessParking', F.col('attributes.BusinessParking'))\ndf = df.withColumn('ByAppointmentOnly', F.col('attributes.ByAppointmentOnly'))\ndf = df.withColumn('Caters', F.col('attributes.Caters'))\ndf = df.withColumn('CoatCheck', F.col('attributes.CoatCheck'))\ndf = df.withColumn('Corkage', F.col('attributes.Corkage'))\ndf = df.withColumn('DietaryRestrictions', F.col('attributes.DietaryRestrictions'))\ndf = df.withColumn('DogsAllowed', F.col('attributes.DogsAllowed'))\ndf = df.withColumn('DriveThru', F.col('attributes.DriveThru'))\ndf = df.withColumn('GoodForDancing', F.col('attributes.GoodForDancing'))\ndf = df.withColumn('GoodForKids', F.col('attributes.GoodForKids'))\ndf = df.withColumn('GoodForMeal', F.col('attributes.GoodForMeal'))\ndf = df.withColumn('HairSpecializesIn', F.col('attributes.HairSpecializesIn'))\ndf = df.withColumn('HappyHour', F.col('attributes.HappyHour'))\ndf = df.withColumn('HasTV', F.col('attributes.HasTV'))\ndf = df.withColumn('Music', F.col('attributes.Music'))\ndf = df.withColumn('NoiseLevel', F.col('attributes.NoiseLevel'))\ndf = df.withColumn('Open24Hours', F.col('attributes.Open24Hours'))\ndf = df.withColumn('OutdoorSeating', F.col('attributes.OutdoorSeating'))\ndf = df.withColumn('RestaurantsAttire', F.col('attributes.RestaurantsAttire'))\ndf = df.withColumn('RestaurantsCounterService', F.col('attributes.RestaurantsCounterService'))\ndf = df.withColumn('RestaurantsDelivery', F.col('attributes.RestaurantsDelivery'))\ndf = df.withColumn('RestaurantsGoodForGroups', F.col('attributes.RestaurantsGoodForGroups'))\ndf = df.withColumn('RestaurantsPriceRange2', F.col('attributes.RestaurantsPriceRange2'))\ndf = df.withColumn('RestaurantsReservations', F.col('attributes.RestaurantsReservations'))\ndf = df.withColumn('RestaurantsTableService', F.col('attributes.RestaurantsTableService'))\ndf = df.withColumn('RestaurantsTakeOut', F.col('attributes.RestaurantsTakeOut'))\ndf = df.withColumn('Smoking', F.col('attributes.Smoking'))\ndf = df.withColumn('WheelchairAccessible', F.col('attributes.WheelchairAccessible'))\ndf = df.withColumn('WiFi', F.col('attributes.WiFi'))\n\ndf =df.drop('attributes', 'hours') \n"}, {"cell_type": "code", "execution_count": 7, "id": "541f0443-4b17-43b5-8e41-98dd61a633d5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- address: string (nullable = true)\n |-- business_id: string (nullable = true)\n |-- categories: string (nullable = true)\n |-- city: string (nullable = true)\n |-- is_open: long (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- name: string (nullable = true)\n |-- postal_code: string (nullable = true)\n |-- review_count: long (nullable = true)\n |-- stars: double (nullable = true)\n |-- state: string (nullable = true)\n |-- AcceptsInsurance: string (nullable = true)\n |-- AgesAllowed: string (nullable = true)\n |-- Alcohol: string (nullable = true)\n |-- Ambience: string (nullable = true)\n |-- BYOB: string (nullable = true)\n |-- BYOBCorkage: string (nullable = true)\n |-- BestNights: string (nullable = true)\n |-- BikeParking: string (nullable = true)\n |-- BusinessAcceptsBitcoin: string (nullable = true)\n |-- BusinessAcceptsCreditCards: string (nullable = true)\n |-- BusinessParking: string (nullable = true)\n |-- ByAppointmentOnly: string (nullable = true)\n |-- Caters: string (nullable = true)\n |-- CoatCheck: string (nullable = true)\n |-- Corkage: string (nullable = true)\n |-- DietaryRestrictions: string (nullable = true)\n |-- DogsAllowed: string (nullable = true)\n |-- DriveThru: string (nullable = true)\n |-- GoodForDancing: string (nullable = true)\n |-- GoodForKids: string (nullable = true)\n |-- GoodForMeal: string (nullable = true)\n |-- HairSpecializesIn: string (nullable = true)\n |-- HappyHour: string (nullable = true)\n |-- HasTV: string (nullable = true)\n |-- Music: string (nullable = true)\n |-- NoiseLevel: string (nullable = true)\n |-- Open24Hours: string (nullable = true)\n |-- OutdoorSeating: string (nullable = true)\n |-- RestaurantsAttire: string (nullable = true)\n |-- RestaurantsCounterService: string (nullable = true)\n |-- RestaurantsDelivery: string (nullable = true)\n |-- RestaurantsGoodForGroups: string (nullable = true)\n |-- RestaurantsPriceRange2: string (nullable = true)\n |-- RestaurantsReservations: string (nullable = true)\n |-- RestaurantsTableService: string (nullable = true)\n |-- RestaurantsTakeOut: string (nullable = true)\n |-- Smoking: string (nullable = true)\n |-- WheelchairAccessible: string (nullable = true)\n |-- WiFi: string (nullable = true)\n\n"}], "source": "df.printSchema()"}, {"cell_type": "code", "execution_count": null, "id": "27920036-2d43-43f4-918d-0a58e8e4dd1b", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 8, "id": "c55de3f6-982e-45c1-924e-7e1d13021019", "metadata": {}, "outputs": [], "source": "# # unwrap nested struct columns \n\n# df1 = df1.withColumn('AcceptsInsurance', F.col('attributes.AcceptsInsurance')) \n# df1 = df1.withColumn('AgesAllowed', F.col('attributes.AgesAllowed')) \n# df1 = df1.withColumn('Alcohol', F.col('attributes.Alcohol')) \n# df1 = df1.withColumn('Ambience', F.col('attributes.Ambience')) \n# df1 = df1.withColumn('BYOB', F.col('attributes.BYOB')) \n# df1 = df1.withColumn('BYOBCorkage', F.col('attributes.BYOBCorkage')) \n# df1 = df1.withColumn('BestNights', F.col('attributes.BestNights')) \n# df1 = df1.withColumn('BikeParking', F.col('attributes.BikeParking')) \n# df1 = df1.withColumn('BusinessAcceptsBitcoin', F.col('attributes.BusinessAcceptsBitcoin')) \n# df1 = df1.withColumn('BusinessAcceptsCreditCards', F.col('attributes.BusinessAcceptsCreditCards')) \n# df1 = df1.withColumn('BusinessParking', F.col('attributes.BusinessParking')) \n# df1 = df1.withColumn('ByAppointmentOnly', F.col('attributes.ByAppointmentOnly')) \n# df1 = df1.withColumn('Caters', F.col('attributes.Caters')) \n# df1 = df1.withColumn('CoatCheck', F.col('attributes.CoatCheck')) \n# df1 = df1.withColumn('Corkage', F.col('attributes.Corkage')) \n# df1 = df1.withColumn('DietaryRestrictions', F.col('attributes.DietaryRestrictions')) \n# df1 = df1.withColumn('DogsAllowed', F.col('attributes.DogsAllowed')) \n# df1 = df1.withColumn('DriveThru', F.col('attributes.DriveThru')) \n# df1 = df1.withColumn('Goodf1orDancing', F.col('attributes.Goodf1orDancing')) \n# df1 = df1.withColumn('Goodf1orKids', F.col('attributes.Goodf1orKids')) \n# df1 = df1.withColumn('Goodf1orMeal', F.col('attributes.Goodf1orMeal')) \n# df1 = df1.withColumn('HairSpecializesIn', F.col('attributes.HairSpecializesIn')) \n# df1 = df1.withColumn('HappyHour', F.col('attributes.HappyHour')) \n# df1 = df1.withColumn('HasTV', F.col('attributes.HasTV')) \n# df1 = df1.withColumn('Music', F.col('attributes.Music')) \n# df1 = df1.withColumn('NoiseLevel', F.col('attributes.NoiseLevel')) \n# df1 = df1.withColumn('Open24Hours', F.col('attributes.Open24Hours')) \n# df1 = df1.withColumn('OutdoorSeating', F.col('attributes.OutdoorSeating')) \n# df1 = df1.withColumn('RestaurantsAttire', F.col('attributes.RestaurantsAttire')) \n# df1 = df1.withColumn('RestaurantsCounterService', F.col('attributes.RestaurantsCounterService')) \n# df1 = df1.withColumn('RestaurantsDelivery', F.col('attributes.RestaurantsDelivery')) \n# df1 = df1.withColumn('RestaurantsGoodf1orGroups', F.col('attributes.RestaurantsGoodf1orGroups')) \n# df1 = df1.withColumn('RestaurantsPriceRange2', F.col('attributes.RestaurantsPriceRange2')) \n# df1 = df1.withColumn('RestaurantsReservations', F.col('attributes.RestaurantsReservations')) \n# df1 = df1.withColumn('RestaurantsTableService', F.col('attributes.RestaurantsTableService')) \n# df1 = df1.withColumn('RestaurantsTakeOut', F.col('attributes.RestaurantsTakeOut')) \n# df1 = df1.withColumn('Smoking', F.col('attributes.Smoking')) \n# df1 = df1.withColumn('WheelchairAccessible', F.col('attributes.WheelchairAccessible')) \n# df1 = df1.withColumn('WiFi', F.col('attributes.WiFi')) \n\n# df1 = df1.withColumn('Friday', F.col('hours.Friday')) \n# df1 = df1.withColumn('Monday', F.col('hours.Monday')) \n# df1 = df1.withColumn('Saturday', F.col('hours.Saturday')) \n# df1 = df1.withColumn('Sunday', F.col('hours.Sunday')) \n# df1 = df1.withColumn('Thursday', F.col('hours.Thursday')) \n# df1 = df1.withColumn('Tuesday', F.col('hours.Tuesday')) \n# df1 = df1.withColumn('Wednesday', F.col('hours.Wednesday')) \n\n# df1 = df1.drop('attributes', 'hours') "}, {"cell_type": "code", "execution_count": 11, "id": "bae132c3-121e-4284-b289-bf7b976b81f6", "metadata": {}, "outputs": [{"ename": "AnalysisException", "evalue": "cannot resolve '`attributes.AcceptsInsurance`' given input columns: [AcceptsInsurance, AgesAllowed, Alcohol, Ambience, BYOB, BYOBCorkage, BestNights, BikeParking, BusinessAcceptsBitcoin, BusinessAcceptsCreditCards, BusinessParking, ByAppointmentOnly, Caters, CoatCheck, Corkage, DietaryRestrictions, DogsAllowed, DriveThru, Friday, GoodForDancing, GoodForKids, GoodForMeal, HairSpecializesIn, HappyHour, HasTV, Monday, Music, NoiseLevel, Open24Hours, OutdoorSeating, RestaurantsAttire, RestaurantsCounterService, RestaurantsDelivery, RestaurantsGoodForGroups, RestaurantsPriceRange2, RestaurantsReservations, RestaurantsTableService, RestaurantsTakeOut, Saturday, Smoking, Sunday, Thursday, Tuesday, Wednesday, WheelchairAccessible, WiFi, address, business_id, categories, city, is_open, latitude, longitude, name, postal_code, review_count, stars, state];\n'Project [address#186, business_id#187, categories#188, city#189, is_open#190L, latitude#191, longitude#192, name#193, postal_code#194, review_count#195L, stars#196, state#197, 'attributes.AcceptsInsurance AS AcceptsInsurance#2124, AgesAllowed#199, Alcohol#200, Ambience#201, BYOB#202, BYOBCorkage#203, BestNights#204, BikeParking#205, BusinessAcceptsBitcoin#206, BusinessAcceptsCreditCards#207, BusinessParking#208, ByAppointmentOnly#209, ... 34 more fields]\n+- Repartition 8, true\n   +- Relation[address#186,business_id#187,categories#188,city#189,is_open#190L,latitude#191,longitude#192,name#193,postal_code#194,review_count#195L,stars#196,state#197,AcceptsInsurance#198,AgesAllowed#199,Alcohol#200,Ambience#201,BYOB#202,BYOBCorkage#203,BestNights#204,BikeParking#205,BusinessAcceptsBitcoin#206,BusinessAcceptsCreditCards#207,BusinessParking#208,ByAppointmentOnly#209,... 34 more fields] parquet\n", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)", "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Unwrap nested struct columns\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAcceptsInsurance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattributes.AcceptsInsurance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df1 \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgesAllowed\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattributes.AgesAllowed\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      6\u001b[0m df1 \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlcohol\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattributes.Alcohol\u001b[39m\u001b[38;5;124m'\u001b[39m))\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:2455\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2426\u001b[0m \u001b[38;5;124;03mReturns a new :class:`DataFrame` by adding a column or replacing the\u001b[39;00m\n\u001b[1;32m   2427\u001b[0m \u001b[38;5;124;03mexisting column that has the same name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \n\u001b[1;32m   2453\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n", "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`attributes.AcceptsInsurance`' given input columns: [AcceptsInsurance, AgesAllowed, Alcohol, Ambience, BYOB, BYOBCorkage, BestNights, BikeParking, BusinessAcceptsBitcoin, BusinessAcceptsCreditCards, BusinessParking, ByAppointmentOnly, Caters, CoatCheck, Corkage, DietaryRestrictions, DogsAllowed, DriveThru, Friday, GoodForDancing, GoodForKids, GoodForMeal, HairSpecializesIn, HappyHour, HasTV, Monday, Music, NoiseLevel, Open24Hours, OutdoorSeating, RestaurantsAttire, RestaurantsCounterService, RestaurantsDelivery, RestaurantsGoodForGroups, RestaurantsPriceRange2, RestaurantsReservations, RestaurantsTableService, RestaurantsTakeOut, Saturday, Smoking, Sunday, Thursday, Tuesday, Wednesday, WheelchairAccessible, WiFi, address, business_id, categories, city, is_open, latitude, longitude, name, postal_code, review_count, stars, state];\n'Project [address#186, business_id#187, categories#188, city#189, is_open#190L, latitude#191, longitude#192, name#193, postal_code#194, review_count#195L, stars#196, state#197, 'attributes.AcceptsInsurance AS AcceptsInsurance#2124, AgesAllowed#199, Alcohol#200, Ambience#201, BYOB#202, BYOBCorkage#203, BestNights#204, BikeParking#205, BusinessAcceptsBitcoin#206, BusinessAcceptsCreditCards#207, BusinessParking#208, ByAppointmentOnly#209, ... 34 more fields]\n+- Repartition 8, true\n   +- Relation[address#186,business_id#187,categories#188,city#189,is_open#190L,latitude#191,longitude#192,name#193,postal_code#194,review_count#195L,stars#196,state#197,AcceptsInsurance#198,AgesAllowed#199,Alcohol#200,Ambience#201,BYOB#202,BYOBCorkage#203,BestNights#204,BikeParking#205,BusinessAcceptsBitcoin#206,BusinessAcceptsCreditCards#207,BusinessParking#208,ByAppointmentOnly#209,... 34 more fields] parquet\n"]}], "source": "from pyspark.sql import functions as F\n\n# Unwrap nested struct columns\ndf1 = df1.withColumn('AcceptsInsurance', F.col('attributes.AcceptsInsurance'))\ndf1 = df1.withColumn('AgesAllowed', F.col('attributes.AgesAllowed'))\ndf1 = df1.withColumn('Alcohol', F.col('attributes.Alcohol'))\ndf1 = df1.withColumn('Ambience', F.col('attributes.Ambience'))\ndf1 = df1.withColumn('BYOB', F.col('attributes.BYOB'))\ndf1 = df1.withColumn('BYOBCorkage', F.col('attributes.BYOBCorkage'))\ndf1 = df1.withColumn('BestNights', F.col('attributes.BestNights'))\ndf1 = df1.withColumn('BikeParking', F.col('attributes.BikeParking'))\ndf1 = df1.withColumn('BusinessAcceptsBitcoin', F.col('attributes.BusinessAcceptsBitcoin'))\ndf1 = df1.withColumn('BusinessAcceptsCreditCards', F.col('attributes.BusinessAcceptsCreditCards'))\ndf1 = df1.withColumn('BusinessParking', F.col('attributes.BusinessParking'))\ndf1 = df1.withColumn('ByAppointmentOnly', F.col('attributes.ByAppointmentOnly'))\ndf1 = df1.withColumn('Caters', F.col('attributes.Caters'))\ndf1 = df1.withColumn('CoatCheck', F.col('attributes.CoatCheck'))\ndf1 = df1.withColumn('Corkage', F.col('attributes.Corkage'))\ndf1 = df1.withColumn('DietaryRestrictions', F.col('attributes.DietaryRestrictions'))\ndf1 = df1.withColumn('DogsAllowed', F.col('attributes.DogsAllowed'))\ndf1 = df1.withColumn('DriveThru', F.col('attributes.DriveThru'))\ndf1 = df1.withColumn('GoodForDancing', F.col('attributes.GoodForDancing'))\ndf1 = df1.withColumn('GoodForKids', F.col('attributes.GoodForKids'))\ndf1 = df1.withColumn('GoodForMeal', F.col('attributes.GoodForMeal'))\ndf1 = df1.withColumn('HairSpecializesIn', F.col('attributes.HairSpecializesIn'))\ndf1 = df1.withColumn('HappyHour', F.col('attributes.HappyHour'))\ndf1 = df1.withColumn('HasTV', F.col('attributes.HasTV'))\ndf1 = df1.withColumn('Music', F.col('attributes.Music'))\ndf1 = df1.withColumn('NoiseLevel', F.col('attributes.NoiseLevel'))\ndf1 = df1.withColumn('Open24Hours', F.col('attributes.Open24Hours'))\ndf1 = df1.withColumn('OutdoorSeating', F.col('attributes.OutdoorSeating'))\ndf1 = df1.withColumn('RestaurantsAttire', F.col('attributes.RestaurantsAttire'))\ndf1 = df1.withColumn('RestaurantsCounterService', F.col('attributes.RestaurantsCounterService'))\ndf1 = df1.withColumn('RestaurantsDelivery', F.col('attributes.RestaurantsDelivery'))\ndf1 = df1.withColumn('RestaurantsGoodForGroups', F.col('attributes.RestaurantsGoodForGroups'))\ndf1 = df1.withColumn('RestaurantsPriceRange2', F.col('attributes.RestaurantsPriceRange2'))\ndf1 = df1.withColumn('RestaurantsReservations', F.col('attributes.RestaurantsReservations'))\ndf1 = df1.withColumn('RestaurantsTableService', F.col('attributes.RestaurantsTableService'))\ndf1 = df1.drop('attributes', 'hours') \n"}, {"cell_type": "code", "execution_count": null, "id": "ba9e72d8-553c-437d-a0fc-bbd217003ff2", "metadata": {}, "outputs": [], "source": "df1.printSchema()"}, {"cell_type": "code", "execution_count": null, "id": "f6448c91-89bd-4af5-8e79-dcb2086eccea", "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import StringIndexer\n\n# Select the categorical columns for string indexing\ncategorical_columns = [\"address\", \"business_id\", \"categories\", \"city\", \"name\", \"postal_code\", \"state\",\n                       \"AcceptsInsurance\", \"AgesAllowed\", \"Alcohol\", \"Ambience\", \"BYOB\", \"BYOBCorkage\",\n                       \"BestNights\", \"BikeParking\", \"BusinessAcceptsBitcoin\", \"BusinessAcceptsCreditCards\",\n                       \"BusinessParking\", \"ByAppointmentOnly\", \"Caters\", \"CoatCheck\", \"Corkage\",\n                       \"DietaryRestrictions\", \"DogsAllowed\", \"DriveThru\", \"GoodForDancing\", \"GoodForKids\",\n                       \"GoodForMeal\", \"HairSpecializesIn\", \"HappyHour\", \"HasTV\", \"Music\", \"NoiseLevel\",\n                       \"Open24Hours\", \"OutdoorSeating\", \"RestaurantsAttire\", \"RestaurantsCounterService\",\n                       \"RestaurantsDelivery\", \"RestaurantsGoodForGroups\", \"RestaurantsPriceRange2\",\n                       \"RestaurantsReservations\", \"RestaurantsTableService\"]\n\n# Create a StringIndexer for each categorical column\nindexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\") for col in categorical_columns]\n\n# Fit the StringIndexers to the data\nindexer_models = [indexer.fit(df) for indexer in indexers]\n\n# Apply string indexing to the data\ndf_indexed = df\nfor indexer_model in indexer_models:\n    df_indexed = indexer_model.transform(df_indexed)\n\n# Select the indexed columns for correlation analysis\nindexed_columns = [col+\"_index\" for col in categorical_columns]\n\n# Calculate the correlation between indexed columns and the \"stars\" column\ncorrelation_matrix = df_indexed.stat.corr(\"stars\", *indexed_columns)\n"}, {"cell_type": "code", "execution_count": null, "id": "7ece2a31-2b63-4fa5-b305-9ff4989097a9", "metadata": {}, "outputs": [], "source": "correlation_matrix = {}\n\n# Calculate the correlation between each indexed column and the \"stars\" column\nfor col in indexed_columns:\n    correlation = df_indexed.stat.corr(\"stars\", col)\n    correlation_matrix[col] = correlation\n"}, {"cell_type": "code", "execution_count": 33, "id": "4f36fd81-cc04-4f27-a08a-a676fd223b10", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['address_index', 'business_id_index', 'categories_index', 'city_index', 'name_index', 'postal_code_index', 'state_index', 'AcceptsInsurance_index', 'AgesAllowed_index', 'Alcohol_index', 'Ambience_index', 'BYOB_index', 'BYOBCorkage_index', 'BestNights_index', 'BikeParking_index', 'BusinessAcceptsBitcoin_index', 'BusinessAcceptsCreditCards_index', 'BusinessParking_index', 'ByAppointmentOnly_index', 'Caters_index', 'CoatCheck_index', 'Corkage_index', 'DietaryRestrictions_index', 'DogsAllowed_index', 'DriveThru_index', 'GoodForDancing_index', 'GoodForKids_index', 'GoodForMeal_index', 'HairSpecializesIn_index', 'HappyHour_index', 'HasTV_index', 'Music_index', 'NoiseLevel_index', 'Open24Hours_index', 'OutdoorSeating_index', 'RestaurantsAttire_index', 'RestaurantsCounterService_index', 'RestaurantsDelivery_index', 'RestaurantsGoodForGroups_index', 'RestaurantsPriceRange2_index', 'RestaurantsReservations_index', 'RestaurantsTableService_index']\n"}], "source": "print(indexed_columns)"}, {"cell_type": "code", "execution_count": 11, "id": "4f8c62ea-acad-4a8e-a03a-e0c66799417c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 10:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+--------------------+-----------+-------+------------+--------------+--------------------+-----------+------------+-----+-----+----------------+-----------+----------+--------------------+----+-----------+--------------------+-----------+----------------------+--------------------------+--------------------+-----------------+------+---------+-------+-------------------+-----------+---------+--------------+-----------+--------------------+-----------------+---------+-----+--------------------+----------+-----------+--------------+-----------------+-------------------------+-------------------+------------------------+----------------------+-----------------------+-----------------------+\n|             address|         business_id|          categories|       city|is_open|    latitude|     longitude|                name|postal_code|review_count|stars|state|AcceptsInsurance|AgesAllowed|   Alcohol|            Ambience|BYOB|BYOBCorkage|          BestNights|BikeParking|BusinessAcceptsBitcoin|BusinessAcceptsCreditCards|     BusinessParking|ByAppointmentOnly|Caters|CoatCheck|Corkage|DietaryRestrictions|DogsAllowed|DriveThru|GoodForDancing|GoodForKids|         GoodForMeal|HairSpecializesIn|HappyHour|HasTV|               Music|NoiseLevel|Open24Hours|OutdoorSeating|RestaurantsAttire|RestaurantsCounterService|RestaurantsDelivery|RestaurantsGoodForGroups|RestaurantsPriceRange2|RestaurantsReservations|RestaurantsTableService|\n+--------------------+--------------------+--------------------+-----------+-------+------------+--------------+--------------------+-----------+------------+-----+-----+----------------+-----------+----------+--------------------+----+-----------+--------------------+-----------+----------------------+--------------------------+--------------------+-----------------+------+---------+-------+-------------------+-----------+---------+--------------+-----------+--------------------+-----------------+---------+-----+--------------------+----------+-----------+--------------+-----------------+-------------------------+-------------------+------------------------+----------------------+-----------------------+-----------------------+\n| 124 E Northfield Dr|REE5upzTnzu0q6DQf...|Fast Food, Food D...| Brownsburg|      1|  39.8573265|   -86.3903223|      Firehouse Subs|      46112|          19|  3.0|   IN|            null|       null|   u'none'|{'romantic': Fals...|null|       null|                null|       True|                  null|                      True|{'garage': False,...|             null|  True|     null|   null|               null|       null|     null|          null|       True|                null|             null|     null| True|                null|u'average'|       null|         False|        u'casual'|                     null|               True|                    True|                     1|                  False|                   null|\n|5210 Windermere B...|PlLFg595QSUAiTKi9...|Nightlife, Bars, ...|   Edmonton|      1|  53.4347854|  -113.6032227|Browns Socialhous...|    T6W 0L9|          99|  3.5|   AB|            null|       null|'full_bar'|{'touristy': Fals...|null|       null|{'monday': False,...|       True|                  null|                      null|{'garage': False,...|             null| False|    False|   null|               null|      False|    False|         False|       True|{'dessert': True,...|             null|     True| True|{'dj': False, 'ba...| 'average'|       null|          True|         'casual'|                     null|               True|                    True|                     2|                   True|                   True|\n|3202 S State Rout...|pjTaBQJ03T5TdmMi6...|Chicken Shop, Chi...|Glen Carbon|      1|38.777711635|-89.9539907202|                 KFC|      62034|          15|  2.5|   IL|            null|       null|   u'none'|{'touristy': Fals...|null|       null|                null|       null|                  null|                      True|{'garage': False,...|             null|  True|     null|   null|               null|       null|     True|          null|       True|                null|             null|     null| null|                null|u'average'|       null|          null|        u'casual'|                     null|               True|                    null|                     1|                  False|                   null|\n+--------------------+--------------------+--------------------+-----------+-------+------------+--------------+--------------------+-----------+------------+-----+-----+----------------+-----------+----------+--------------------+----+-----------+--------------------+-----------+----------------------+--------------------------+--------------------+-----------------+------+---------+-------+-------------------+-----------+---------+--------------+-----------+--------------------+-----------------+---------+-----+--------------------+----------+-----------+--------------+-----------------+-------------------------+-------------------+------------------------+----------------------+-----------------------+-----------------------+\nonly showing top 3 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "df1.show(3)"}, {"cell_type": "code", "execution_count": 26, "id": "8c67eacd-64c2-4adc-a0e7-28f339abef14", "metadata": {}, "outputs": [], "source": "# Select only the relevant columns\nbusiness_df1 = df1.select(\"business_id\", \"categories\", \"city\", \"stars\", \"review_count\", \"RestaurantsPriceRange2\",\"Ambience\").where(df1['is_open']==1)\n\n# Remove duplicates and missing values\nbusiness_df1 = business_df1.dropDuplicates([\"business_id\"]).na.drop()\n\n# Remove outliers\nbusiness_df1 = business_df1.filter(\"review_count > 5 and review_count < 1000 and stars > 1 and stars < 5 and RestaurantsPriceRange2 is not null\")"}, {"cell_type": "code", "execution_count": 27, "id": "c8c787e2-c6e0-40a6-899e-f286f01c4ef7", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 179:>                                                        (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+-------------+-----+------------+----------------------+--------------------+\n|         business_id|          categories|         city|stars|review_count|RestaurantsPriceRange2|            Ambience|\n+--------------------+--------------------+-------------+-----+------------+----------------------+--------------------+\n|-0iIxySkp97WNlwK6...|Caterers, Sandwic...|         Reno|  3.5|         219|                     1|{'touristy': Fals...|\n|-ZzCVD9Ge7KCy4ffh...|Restaurants, Food...|     Glenside|  4.0|          29|                     1|{'touristy': Fals...|\n|-ajaASaDA_77I6pK3...|Mexican, Restaura...| Mount Laurel|  2.0|         101|                     1|{'romantic': Fals...|\n|0wZJkj-OnZ7Pmubls...|Italian, French, ...|  New Orleans|  4.0|         506|                     1|{'touristy': Fals...|\n|10KnzbTaz-Yq8wADX...|Nightlife, Arts &...|    Nashville|  4.0|          76|                     2|{'touristy': Fals...|\n|1B59ZyvK_n4E1egxq...|American (Traditi...|       Arnold|  2.0|          13|                     1|{'romantic': Fals...|\n|1Du1NruqJwxnzgEUH...|Restaurants, Amer...|Santa Barbara|  4.5|         208|                     2|{u'divey': False,...|\n|1KJ-RZPlWo_wLA_VJ...|Pizza, Nightlife,...|        Tampa|  4.0|         100|                     1|{'touristy': Fals...|\n|23j2d-xD8ZHiQ72Zi...|Southern, Restaur...|        Aston|  3.0|          14|                     1|{'romantic': Fals...|\n+--------------------+--------------------+-------------+-----+------------+----------------------+--------------------+\nonly showing top 9 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "business_df1.show(9)"}, {"cell_type": "code", "execution_count": 14, "id": "e7870050-ba61-47bb-9eaa-e63a3a555bbd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|          categories|\n+--------------------+\n|Caterers, Sandwic...|\n|Restaurants, Food...|\n|Mexican, Restaura...|\n|Italian, French, ...|\n|Nightlife, Arts &...|\n|American (Traditi...|\n|Restaurants, Amer...|\n|Pizza, Nightlife,...|\n|Southern, Restaur...|\n|Caribbean, Restau...|\n|Restaurants, Stea...|\n|Restaurants, Seafood|\n|Restaurants, Chin...|\n|Event Planning & ...|\n|Fast Food, Sandwi...|\n|Restaurants, Amer...|\n|Nightlife, Event ...|\n|Cajun/Creole, Res...|\n|Pizza, Restaurant...|\n|Restaurants, Fast...|\n+--------------------+\nonly showing top 20 rows\n\n"}], "source": "business_df1.select('categories').show()"}, {"cell_type": "code", "execution_count": 15, "id": "23bbc8a8-a40d-433d-8543-92dab890e524", "metadata": {}, "outputs": [], "source": "# from pyspark.sql.functions import udf\n# from pyspark.sql.types import IntegerType, FloatType\n# from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\n# # Create a feature engineering pipeline\n# category_count = udf(lambda x: len(x.split(\",\")), IntegerType())\n# category_avg_length = udf(lambda x: sum([len(c.strip()) for c in x.split(\",\")]) / len(x.split(\",\")), FloatType())\n\n# indexer = StringIndexer(inputCol=\"RestaurantsPriceRange2\", outputCol=\"PriceRangeIndex\")\n# encoder = OneHotEncoder(inputCol=\"PriceRangeIndex\", outputCol=\"PriceRangeVec\")\n\n# assembler = VectorAssembler(inputCols=[\"category_count\", \"category_avg_length\", \"PriceRangeVec\", \"review_count\"], outputCol=\"features\")\n\n# # Fit the feature engineering pipeline to the data\n# business_df1 = business_df1.withColumn(\"category_count\", category_count(\"categories\"))\n# business_df1 = business_df1.withColumn(\"category_avg_length\", category_avg_length(\"categories\"))\n\n# business_df1 = indexer.fit(business_df1).transform(business_df1)\n# business_df1 = encoder.fit(business_df1).transform(business_df1)\n# business_df1 = assembler.transform(business_df1)\n"}, {"cell_type": "code", "execution_count": 16, "id": "0dba5330-ce25-4544-8f00-fc93e05a80a0", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n\n# Create StringIndexer for the RestaurantsPriceRange2 column\nprice_range_indexer = StringIndexer(inputCol=\"RestaurantsPriceRange2\", outputCol=\"PriceRangeIndex\")\n\n# Fit the indexer to the data\nprice_range_indexer_model = price_range_indexer.fit(business_df1)\nbusiness_df1 = price_range_indexer_model.transform(business_df1)\n\n# Apply OneHotEncoder to the PriceRangeIndex column\nprice_range_encoder = OneHotEncoder(inputCols=[\"PriceRangeIndex\"], outputCols=[\"PriceRangeVec\"])\nprice_range_encoder_model = price_range_encoder.fit(business_df1)\nbusiness_df1 = price_range_encoder_model.transform(business_df1)\n\n# Create StringIndexer for the categories column\ncategory_indexer = StringIndexer(inputCol=\"categories\", outputCol=\"category_index\")\n\n# Fit the indexer to the data\ncategory_indexer_model = category_indexer.fit(business_df1)\nbusiness_df1 = category_indexer_model.transform(business_df1)\n\n# Apply OneHotEncoder to the category_index column\ncategory_encoder = OneHotEncoder(inputCols=[\"category_index\"], outputCols=[\"category_vec\"])\ncategory_encoder_model = category_encoder.fit(business_df1)\nbusiness_df1 = category_encoder_model.transform(business_df1)\n\n# Define the feature columns for VectorAssembler\nfeature_columns = [\"PriceRangeVec\", \"review_count\",\"category_vec\"]\n\n# Create VectorAssembler to combine features into a single vector\nassembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n\n# Transform the data using the assembler\nbusiness_df1 = assembler.transform(business_df1)\n"}, {"cell_type": "code", "execution_count": 17, "id": "e04f9454-10bb-4a81-a577-ce8e036751a2", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/05/17 15:32:51 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1703.2 KiB\n"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+------------+-----+------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+\n|         business_id|          categories|        city|stars|review_count|RestaurantsPriceRange2|PriceRangeIndex|PriceRangeVec|category_index|        category_vec|            features|\n+--------------------+--------------------+------------+-----+------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+\n|-0iIxySkp97WNlwK6...|Caterers, Sandwic...|        Reno|  3.5|         219|                     1|            1.0|(4,[1],[1.0])|        5254.0|(17595,[5254],[1.0])|(17600,[1,4,5259]...|\n|-ZzCVD9Ge7KCy4ffh...|Restaurants, Food...|    Glenside|  4.0|          29|                     1|            1.0|(4,[1],[1.0])|       13496.0|(17595,[13496],[1...|(17600,[1,4,13501...|\n|-ajaASaDA_77I6pK3...|Mexican, Restaura...|Mount Laurel|  2.0|         101|                     1|            1.0|(4,[1],[1.0])|          64.0|  (17595,[64],[1.0])|(17600,[1,4,69],[...|\n+--------------------+--------------------+------------+-----+------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+\nonly showing top 3 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "business_df1.show(3)"}, {"cell_type": "code", "execution_count": 9, "id": "fb264337-b4e7-44b5-8f9c-427430d817fb", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# from pyspark.sql.functions import udf1\n# from pyspark.sql.types import IntegerType, FloatType\n# from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\n# # Create a feature engineering pipeline\n# category_count = udf1(lambda x: len(x.split(\",\")), IntegerType())\n# category_avg_length = udf1(lambda x: sum([len(c.strip()) for c in x.split(\",\")])/len(x.split(\",\")), FloatType())\n# city_popularity = udf1(lambda x: city_popularity_dict[x], FloatType())\n\n# indexer = StringIndexer(inputCol=\"RestaurantsPriceRange2\", outputCol=\"PriceRangeIndex\")\n# encoder = OneHotEncoder(inputCol=\"PriceRangeIndex\", outputCol=\"PriceRangeVec\")\n\n# assembler = VectorAssembler(inputCols=[\"category_count\", \"category_avg_length\", \"city_popularity\", \"PriceRangeVec\", \"review_count\"], outputCol=\"features\")\n\n# # Fit the feature engineering pipeline to the data\n# business_df1 = business_df1.withColumn(\"category_count\", category_count(\"categories\"))\n# business_df1 = business_df1.withColumn(\"category_avg_length\", category_avg_length(\"categories\"))\n# business_df1 = business_df1.withColumn(\"city_popularity\", city_popularity(\"city\"))\n\n# business_df1 = indexer.fit(business_df1).transform(business_df1)\n# business_df1 = encoder.fit(business_df1).transform(business_df1)\n# business_df1 = assembler.transform(business_df1)\n"}, {"cell_type": "code", "execution_count": 16, "id": "74d5f61a-ec01-4350-b4d1-073adafc45f6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.ml.regression import LinearRegression\n\n# Split the data into training and testing sets\n(training_data, testing_data) = business_df1.randomSplit([0.7, 0.3])\n\n# Train the machine learning model\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"stars\", maxIter=100, regParam=0.3, elasticNetParam=0.8)\nlr_model = lr.fit(training_data)\n\n# Evaluate the machine learning model\npredictions = lr_model.transform(testing_data)\nmse = predictions.selectExpr(\"avg(pow(stars - prediction, 2))\").first()[0]\nr2 = lr_model.summary.r2\n"}, {"cell_type": "code", "execution_count": 17, "id": "7687536c-93c4-4683-bcfd-ab6ee2bf2551", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 91:==============>                                           (1 + 3) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+----------------+-----+------------+----------------------+--------------+-------------------+---------------+-------------+--------------------+------------------+\n|         business_id|          categories|            city|stars|review_count|RestaurantsPriceRange2|category_count|category_avg_length|PriceRangeIndex|PriceRangeVec|            features|        prediction|\n+--------------------+--------------------+----------------+-----+------------+----------------------+--------------+-------------------+---------------+-------------+--------------------+------------------+\n|-ZzCVD9Ge7KCy4ffh...|Restaurants, Food...|        Glenside|  4.0|          29|                     1|             4|              11.75|            1.0|(4,[1],[1.0])|[4.0,11.75,0.0,1....|3.4828921945637696|\n|0Y8xQvpbmO02SsFZt...|Restaurants, Fast...|       Bridgeton|  2.0|          19|                     1|             3|                9.0|            1.0|(4,[1],[1.0])|[3.0,9.0,0.0,1.0,...|3.4828921945637696|\n|0YI4tyK4MrTAveuj2...|Hot Dogs, Sandwic...|      Isla Vista|  4.5|          24|                     1|             6|           9.166667|            1.0|(4,[1],[1.0])|[6.0,9.1666669845...|3.4828921945637696|\n|1p5s3NpQZHnaZUWT1...|  Uniforms, Shopping|        Edmonton|  2.5|           7|                     2|             2|                8.0|            0.0|(4,[0],[1.0])|[2.0,8.0,1.0,0.0,...|3.4828921945637696|\n|23j2d-xD8ZHiQ72Zi...|Southern, Restaur...|           Aston|  3.0|          14|                     1|             3|          10.666667|            1.0|(4,[1],[1.0])|[3.0,10.666666984...|3.4828921945637696|\n|2BVVhR_Bg6aOu4-hf...|Restaurants, Italian|           Aston|  3.5|          19|                     2|             2|                9.0|            0.0|(4,[0],[1.0])|[2.0,9.0,1.0,0.0,...|3.4828921945637696|\n|2UDJpaTsYHu9CXmbU...|Restaurants, Seafood|         Horsham|  3.0|          45|                     3|             2|                9.0|            2.0|(4,[2],[1.0])|[2.0,9.0,0.0,0.0,...|3.4828921945637696|\n|2rR0dcyydaleMzJGG...|Event Planning & ...|       Nashville|  4.0|         129|                     3|             6|          11.666667|            2.0|(4,[2],[1.0])|[6.0,11.666666984...|3.4828921945637696|\n|2y_CdkxEOJEJGyJAp...|Restaurants, Amer...|    Woolwich Twp|  3.5|         104|                     2|             2|               16.5|            0.0|(4,[0],[1.0])|[2.0,16.5,1.0,0.0...|3.4828921945637696|\n|3FKIev7ZB_KE6XHL9...|Nightlife, Event ...|    Philadelphia|  4.0|         443|                     2|             7|               15.0|            0.0|(4,[0],[1.0])|[7.0,15.0,1.0,0.0...|3.4828921945637696|\n|6WmOJ8ARLjDUvqtHu...|  Restaurants, Pizza|        Metairie|  4.0|         120|                     2|             2|                8.0|            0.0|(4,[0],[1.0])|[2.0,8.0,1.0,0.0,...|3.4828921945637696|\n|7SmFNkyXl2K1RIomu...|Shopping, Arts & ...|     New Orleans|  4.0|           6|                     2|            16|            11.5625|            0.0|(4,[0],[1.0])|[16.0,11.5625,1.0...|3.4828921945637696|\n|7hRaOnXRRS8q620F6...|Nightlife, Sports...|     Saint Louis|  3.5|         220|                     2|             7|          10.714286|            0.0|(4,[0],[1.0])|[7.0,10.714285850...|3.4828921945637696|\n|7u3LzhyxgPMo__24R...|Breakfast & Brunc...|       Nashville|  3.5|         318|                     2|             5|               11.2|            0.0|(4,[0],[1.0])|[5.0,11.199999809...|3.4828921945637696|\n|8eUygCpxOl_oPC5gk...|Department Stores...|Fairview Heights|  2.5|           7|                     2|             3|          10.666667|            0.0|(4,[0],[1.0])|[3.0,10.666666984...|3.4828921945637696|\n|9F9RxnKQ_oi0nr1Im...|Pizza, Restaurant...|   Wesley Chapel|  3.5|          64|                     2|             3|          7.6666665|            0.0|(4,[0],[1.0])|[3.0,7.6666665077...|3.4828921945637696|\n|9hE1UNgpiGlXYdHis...|Shoe Stores, Shop...|      Wilmington|  4.5|          14|                     2|             3|           8.666667|            0.0|(4,[0],[1.0])|[3.0,8.6666669845...|3.4828921945637696|\n|AZ42H2kk4JUiskC9N...|Bars, Cajun/Creol...|     New Orleans|  4.5|         474|                     2|             5|               11.6|            0.0|(4,[0],[1.0])|[5.0,11.600000381...|3.4828921945637696|\n|BJOGo_upuBElDT_xO...|Nightlife, Seafoo...|          Tucson|  4.5|         472|                     4|             6|                8.5|            3.0|(4,[3],[1.0])|[6.0,8.5,0.0,0.0,...|3.4828921945637696|\n|BXDV7WRidHmDl-JwL...|Restaurants, Fren...|    Philadelphia|  4.0|          14|                     1|             3|                9.0|            1.0|(4,[1],[1.0])|[3.0,9.0,0.0,1.0,...|3.4828921945637696|\n+--------------------+--------------------+----------------+-----+------------+----------------------+--------------+-------------------+---------------+-------------+--------------------+------------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "predictions.show(20)"}, {"cell_type": "code", "execution_count": 18, "id": "781b8538-bd21-43a0-b302-efaea4dc57af", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# from pyspark.ml.regression import DecisionTreeRegressor\n\n# # Split the data into training and testing sets\n# (training_data, testing_data) = business_df1.randomSplit([0.7, 0.3])\n\n# # Create a DecisionTreeRegressor\n# dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"stars\")\n\n# # Train the decision tree model\n# dt_model = dt.fit(training_data)\n\n# # Make predictions on the testing data\n# predictions = dt_model.transform(testing_data)\n\n# # Evaluate the model\n# mse = predictions.selectExpr(\"avg(pow(stars - prediction, 2))\").first()[0]\n"}, {"cell_type": "code", "execution_count": 18, "id": "fb2f7fe0-4262-4144-8cb1-eb67a06023a5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/05/17 15:33:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n23/05/17 15:33:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n23/05/17 15:33:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n23/05/17 15:33:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n23/05/17 15:33:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n23/05/17 15:34:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n23/05/17 15:34:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n23/05/17 15:35:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n23/05/17 15:35:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n23/05/17 15:35:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n[Stage 99:=================================>                        (4 + 2) / 7]\r"}, {"name": "stdout", "output_type": "stream", "text": "Validation MSE: 0.5357591627414421\nTesting MSE: 0.5398328655169513\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.ml.regression import DecisionTreeRegressor\n\n# Split the data into training, validation, and testing sets\n(training_data, validation_data, testing_data) = business_df1.randomSplit([0.7, 0.15, 0.15])\n\n# Create a DecisionTreeRegressor\ndt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"stars\")\n\n# Train the decision tree model\ndt_model = dt.fit(training_data)\n\n# Make predictions on the validation data\nvalidation_predictions = dt_model.transform(validation_data)\n\n# Evaluate the model on the validation data\nvalidation_mse = validation_predictions.selectExpr(\"avg(pow(stars - prediction, 2))\").first()[0]\n\n# Make predictions on the testing data\ntesting_predictions = dt_model.transform(testing_data)\n\n# Evaluate the model on the testing data\ntesting_mse = testing_predictions.selectExpr(\"avg(pow(stars - prediction, 2))\").first()[0]\n\n# Print the evaluation metrics\nprint(\"Validation MSE:\", validation_mse)\nprint(\"Testing MSE:\", testing_mse)\n"}, {"cell_type": "code", "execution_count": 19, "id": "e57b885c-6386-42d2-bc44-e9cf89143214", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/05/17 15:36:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+------------+-----+------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+------------------+\n|         business_id|          categories|        city|stars|review_count|RestaurantsPriceRange2|PriceRangeIndex|PriceRangeVec|category_index|        category_vec|            features|        prediction|\n+--------------------+--------------------+------------+-----+------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+------------------+\n|2fJ-WxJlUN6azp3bz...|Restaurants, Chin...|Philadelphia|  4.0|         485|                     1|            1.0|(4,[1],[1.0])|         511.0| (17595,[511],[1.0])|(17600,[1,4,516],...| 4.016081871345029|\n|2y_CdkxEOJEJGyJAp...|Restaurants, Amer...|Woolwich Twp|  3.5|         104|                     2|            0.0|(4,[0],[1.0])|          25.0|  (17595,[25],[1.0])|(17600,[0,4,30],[...|3.7110181997048697|\n|3wLmMcYDXWkiAjLCF...|Pizza, Restaurant...|    Edmonton|  4.0|          31|                     2|            0.0|(4,[0],[1.0])|       11622.0|(17595,[11622],[1...|(17600,[0,4,11627...| 3.448791348600509|\n|4HMXL85u_wX0WEHuc...|Burgers, Hot Dogs...| Creve Coeur|  3.5|         178|                     1|            1.0|(4,[1],[1.0])|        4705.0|(17595,[4705],[1.0])|(17600,[1,4,4710]...|3.8489208633093526|\n|9xPOQKtIDVaI_fN3n...|Delis, Burgers, N...|Indianapolis|  4.0|         213|                     2|            0.0|(4,[0],[1.0])|        6233.0|(17595,[6233],[1.0])|(17600,[0,4,6238]...| 3.879513343799058|\n|Honx3MgPQuiG72yA0...|Restaurants, Chin...|       Camby|  3.0|          37|                     1|            1.0|(4,[1],[1.0])|         508.0| (17595,[508],[1.0])|(17600,[1,4,513],...| 3.007260845888546|\n|KBza-wFbrUHipbJjk...|Chinese, Restaurants|  Belleville|  3.5|          16|                     1|            1.0|(4,[1],[1.0])|           3.0|   (17595,[3],[1.0])|(17600,[1,4,8],[1...| 3.007260845888546|\n|L5rH_ypwqJcBByVac...|Fast Food, Hot Do...|   St. Louis|  3.5|          92|                     2|            0.0|(4,[0],[1.0])|        7184.0|(17595,[7184],[1.0])|(17600,[0,4,7189]...|3.5972927241962775|\n|Lb2IksLafq3ay-Rxo...|Pubs, Nightlife, ...| Drexel Hill|  4.0|          68|                     2|            0.0|(4,[0],[1.0])|       11798.0|(17595,[11798],[1...|(17600,[0,4,11803...|3.5972927241962775|\n|OTidyJ0pcVB6d73Fl...|Coffee & Tea, Foo...| Cherry Hill|  4.0|           8|                     2|            0.0|(4,[0],[1.0])|          79.0|  (17595,[79],[1.0])|(17600,[0,4,84],[...|3.3149606299212597|\n|PrRZhBIzflSYeNd8L...|Chinese, Restaurants| Palm Harbor|  4.0|          22|                     1|            1.0|(4,[1],[1.0])|           3.0|   (17595,[3],[1.0])|(17600,[1,4,8],[1...| 3.007260845888546|\n|UmBShc01EQd7oasT1...|Restaurants, Sand...| Saint Louis|  3.0|          16|                     1|            1.0|(4,[1],[1.0])|         243.0| (17595,[243],[1.0])|(17600,[1,4,248],...| 3.007260845888546|\n|VEL4jtlIlHoLmjLYd...|Fast Food, Restau...|        Reno|  2.5|          45|                     1|            1.0|(4,[1],[1.0])|           8.0|   (17595,[8],[1.0])|(17600,[1,4,13],[...| 3.378140703517588|\n|VdB1YL718sAxae12P...|Restaurants, Chin...|   Nashville|  4.0|         119|                     2|            0.0|(4,[0],[1.0])|       12862.0|(17595,[12862],[1...|(17600,[0,4,12867...|3.7110181997048697|\n|aI3B47Y_AUYFP5K5J...|American (New), B...| Saint Louis|  4.5|         793|                     2|            0.0|(4,[0],[1.0])|        1724.0|(17595,[1724],[1.0])|(17600,[0,4,1729]...| 3.879513343799058|\n|gsscUrw2B2z2h8PBL...|Restaurants, Sala...|   Greenwood|  3.5|         280|                     2|            0.0|(4,[0],[1.0])|       14383.0|(17595,[14383],[1...|(17600,[0,4,14388...| 3.879513343799058|\n|h3mMPUeFLnd6Jjlzt...|Chinese, Restaura...|  Wilmington|  3.0|          34|                     2|            0.0|(4,[0],[1.0])|        5636.0|(17595,[5636],[1.0])|(17600,[0,4,5641]...| 3.448791348600509|\n|mLh1NbiTmvIx-4oDq...|Cocktail Bars, Ba...|Indianapolis|  3.0|         132|                     2|            0.0|(4,[0],[1.0])|        5702.0|(17595,[5702],[1.0])|(17600,[0,4,5707]...|3.7110181997048697|\n|rQyJXOiZ39eRJ2l9O...|Indian, Bakeries,...| Saint Louis|  4.0|         159|                     2|            0.0|(4,[0],[1.0])|        9377.0|(17595,[9377],[1.0])|(17600,[0,4,9382]...|3.7110181997048697|\n|tdcGR0mEw-OmbRqNi...|Restaurants, Fast...|      Sparks|  2.0|          21|                     1|            1.0|(4,[1],[1.0])|         104.0| (17595,[104],[1.0])|(17600,[1,4,109],...| 3.007260845888546|\n+--------------------+--------------------+------------+-----+------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+------------------+\nonly showing top 20 rows\n\n"}], "source": "testing_predictions.show()"}, {"cell_type": "code", "execution_count": 20, "id": "ccc40e92-4a4e-4c36-9659-1d82022937c8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/05/17 15:36:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+-------------+-----+------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+------------------+\n|         business_id|          categories|         city|stars|review_count|RestaurantsPriceRange2|PriceRangeIndex|PriceRangeVec|category_index|        category_vec|            features|        prediction|\n+--------------------+--------------------+-------------+-----+------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+------------------+\n|6WmOJ8ARLjDUvqtHu...|  Restaurants, Pizza|     Metairie|  4.0|         120|                     2|            0.0|(4,[0],[1.0])|           0.0|   (17595,[0],[1.0])|(17600,[0,4,5],[1...|3.7110181997048697|\n|8IOOFeWwW9p8auITe...|Restaurants, Cafe...| Indianapolis|  4.0|          20|                     2|            0.0|(4,[0],[1.0])|         734.0| (17595,[734],[1.0])|(17600,[0,4,739],...| 3.448791348600509|\n|BJOGo_upuBElDT_xO...|Nightlife, Seafoo...|       Tucson|  4.5|         472|                     4|            3.0|(4,[3],[1.0])|       11111.0|(17595,[11111],[1...|(17600,[3,4,11116...| 4.016081871345029|\n|CBrD7r4PTCAKc7sP_...|Noodles, Asian Fu...| Indianapolis|  4.5|         178|                     2|            0.0|(4,[0],[1.0])|       11193.0|(17595,[11193],[1...|(17600,[0,4,11198...|3.7110181997048697|\n|D88YfiD-nAVRJDkex...|Food, Tex-Mex, Re...|   Plant City|  1.5|          28|                     1|            1.0|(4,[1],[1.0])|        8780.0|(17595,[8780],[1.0])|(17600,[1,4,8785]...| 3.007260845888546|\n|EEOgBTYNuaAHDSOBX...|Restaurants, Coff...| Indianapolis|  3.0|          13|                     1|            1.0|(4,[1],[1.0])|         386.0| (17595,[386],[1.0])|(17600,[1,4,391],...| 3.007260845888546|\n|FkXzqvQiagj9eCgLV...|Restaurants, Japa...|        Tampa|  4.5|          46|                     2|            0.0|(4,[0],[1.0])|          56.0|  (17595,[56],[1.0])|(17600,[0,4,61],[...|3.5588752196836557|\n|IiatvDg0R1qwPtKPm...|Restaurants, Chinese|   Norristown|  4.0|          29|                     2|            0.0|(4,[0],[1.0])|           1.0|   (17595,[1],[1.0])|(17600,[0,4,6],[1...| 3.448791348600509|\n|Ixr2-GfYKatXdq1rZ...|   Restaurants, Thai|       Newark|  3.5|          22|                     1|            1.0|(4,[1],[1.0])|          22.0|  (17595,[22],[1.0])|(17600,[1,4,27],[...| 3.007260845888546|\n|NLV0ppsHTiJk6JVdF...|Thai, Breakfast &...|       Tucson|  4.5|         356|                     1|            1.0|(4,[1],[1.0])|       17171.0|(17595,[17171],[1...|(17600,[1,4,17176...| 4.016081871345029|\n|QKQnFTZzCXyr0NIi9...|Fast Food, Burger...|Saint Charles|  1.5|          23|                     1|            1.0|(4,[1],[1.0])|        1046.0|(17595,[1046],[1.0])|(17600,[1,4,1051]...| 3.007260845888546|\n|W26UivCfmMj1AIpDr...|Steakhouses, Rest...|         Reno|  4.0|         107|                     3|            2.0|(4,[2],[1.0])|       16818.0|(17595,[16818],[1...|(17600,[2,4,16823...|3.8489208633093526|\n|XRTd7lNHKKioXI1A9...|Nightlife, Restau...|       Tucson|  3.5|         104|                     2|            0.0|(4,[0],[1.0])|       10954.0|(17595,[10954],[1...|(17600,[0,4,10959...|3.7110181997048697|\n|clHDwRspNDO5hOyyM...|  Restaurants, Pizza|      Brandon|  2.5|          26|                     1|            1.0|(4,[1],[1.0])|           0.0|   (17595,[0],[1.0])|(17600,[1,4,5],[1...| 3.007260845888546|\n|eXMfOA7nAh3dlLgyw...|Italian, Restaura...| Indianapolis|  4.0|         212|                     2|            0.0|(4,[0],[1.0])|         112.0| (17595,[112],[1.0])|(17600,[0,4,117],...| 3.879513343799058|\n|lpbt16sSm4BTcfeq4...|Restaurants, Chinese|   Norristown|  3.5|          52|                     1|            1.0|(4,[1],[1.0])|           1.0|   (17595,[1],[1.0])|(17600,[1,4,6],[1...| 3.378140703517588|\n|qqtGFnjyZWV--_Yqa...|Mexican, Restaurants|    Pottstown|  3.5|         142|                     2|            0.0|(4,[0],[1.0])|           5.0|   (17595,[5],[1.0])|(17600,[0,4,10],[...|3.7110181997048697|\n|rugDoz-A6vL-FG-8P...|American (New), I...|       Newark|  3.5|         221|                     2|            0.0|(4,[0],[1.0])|        1841.0|(17595,[1841],[1.0])|(17600,[0,4,1846]...| 3.879513343799058|\n|xFk-YQHQ7bkRdwEdW...|Restaurants, Seafood|       Tucson|  4.5|          65|                     2|            0.0|(4,[0],[1.0])|          34.0|  (17595,[34],[1.0])|(17600,[0,4,39],[...|3.5588752196836557|\n|y6aBgF8SQ3PpR6AaW...|American (Traditi...|        Tampa|  2.0|          38|                     1|            1.0|(4,[1],[1.0])|        2304.0|(17595,[2304],[1.0])|(17600,[1,4,2309]...| 3.007260845888546|\n+--------------------+--------------------+-------------+-----+------------+----------------------+---------------+-------------+--------------+--------------------+--------------------+------------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "23/05/17 15:36:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n"}], "source": "validation_predictions.show(20)"}, {"cell_type": "code", "execution_count": 32, "id": "faa61785-507c-4c02-9f63-c9f64326cda8", "metadata": {}, "outputs": [{"ename": "NameError", "evalue": "name 'predictions' is not defined", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictions\u001b[49m\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m20\u001b[39m)\n", "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"]}], "source": "predictions.show(20)"}, {"cell_type": "code", "execution_count": 21, "id": "77b4cc93-dcd9-4492-91b4-3cf7e40e92f0", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/05/17 15:36:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n23/05/17 15:36:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n23/05/17 15:36:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n23/05/17 15:36:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n23/05/17 15:36:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n23/05/17 15:36:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.6 MiB\n                                                                                \r"}], "source": "threshold = 3.5  # Example threshold value\n\npredictions = testing_predictions.withColumn(\"predicted_label\", when(testing_predictions[\"prediction\"] >= threshold, 1).otherwise(0))\ntotal_count = testing_predictions.count()\ncorrect_count = predictions.filter((predictions[\"stars\"] >= threshold) & (predictions[\"predicted_label\"] == 1) |\n                                   (predictions[\"stars\"] < threshold) & (predictions[\"predicted_label\"] == 0)).count()\n\naccuracy = correct_count / total_count\ntp = predictions.filter((predictions[\"stars\"] >= threshold) & (predictions[\"predicted_label\"] == 1)).count()\ntn = predictions.filter((predictions[\"stars\"] < threshold) & (predictions[\"predicted_label\"] == 0)).count()\nfp = predictions.filter((predictions[\"stars\"] < threshold) & (predictions[\"predicted_label\"] == 1)).count()\nfn = predictions.filter((predictions[\"stars\"] >= threshold) & (predictions[\"predicted_label\"] == 0)).count()\n\nprecision = tp / (tp + fp)\nrecall = tp / (tp + fn)\nf1_score = 2 * (precision * recall) / (precision + recall)\n# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# # Define the threshold for positive class\n# threshold = 3.5\n\n# # Convert the regression predictions to binary labels\n# predictions = predictions.withColumn(\"predicted_label\", when(predictions[\"prediction\"] >= threshold, 1).otherwise(0))\n\n# # Create a MulticlassClassificationEvaluator\n# evaluator = MulticlassClassificationEvaluator(labelCol=\"stars\", predictionCol=\"predicted_label\", metricName=\"accuracy\")\n\n# # Calculate accuracy\n# accuracy = evaluator.evaluate(predictions)\n\n# # Calculate F1 score\n# f1_score = evaluator.setMetricName(\"f1\").evaluate(predictions)\n"}, {"cell_type": "code", "execution_count": 22, "id": "d0ed6741-ec71-4d18-bb4c-ae36f3c334db", "metadata": {}, "outputs": [{"data": {"text/plain": "0.7007824064284205"}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": "f1_score"}, {"cell_type": "code", "execution_count": 23, "id": "f4eb9d61-da36-4d34-a5a8-fa59299e8297", "metadata": {}, "outputs": [{"data": {"text/plain": "0.621530382595649"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "recall"}, {"cell_type": "code", "execution_count": 24, "id": "b854afb4-3aac-4f08-9651-ddbd49720db4", "metadata": {}, "outputs": [{"data": {"text/plain": "0.6555501460564752"}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}], "source": "accuracy"}, {"cell_type": "code", "execution_count": 25, "id": "298de8e5-7b47-4de3-9237-6f80cb80b61e", "metadata": {}, "outputs": [{"data": {"text/plain": "0.8031992244304411"}, "execution_count": 25, "metadata": {}, "output_type": "execute_result"}], "source": "precision"}, {"cell_type": "code", "execution_count": null, "id": "e7fc5a2f-e599-425c-9f6a-a3715d760a38", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}